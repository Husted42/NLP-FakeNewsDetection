{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (1-6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>What difficulties or limitations are there when using regular expressions?</strong> <br>\n",
    "I found that the capabilities are the same when using either BeautifulSoup or re, but the implementation gets significantly more manageable when using BeautifulSoup. <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RequestList\n",
      "['Accessibility links', 'News Navigation', 'BBC News Home', 'Breaking Breaking news ', 'Top Stories', 'Greek transport minister resigns after deadly train crash', 'Greek transport minister resigns after deadly train crash', 'Related content', 'At the crash site of no hope - BBC reporter in Greece', 'Covid origin likely China lab incident - FBI chief', 'Why the Covid lab-leak theory is being taken seriously ', 'Ruling party wins Nigerias presidential election', 'Ed Sheeran says wife developed tumour in pregnancy', 'Uranium particles enriched to 83.7% found in Iran', 'Bieber cancels remaining Justice world tour dates', 'Man survives 31 days in jungle by eating worms', 'Kobe Bryant widow wins $29m settlement from LA', 'Denmark scraps holiday to boost defence budget', 'Kobe Bryant widow wins $29m settlement from LA', 'Denmark scraps holiday to boost defence budget', 'Israel cracks down on judicial reform protests', 'World Cup record holder Fontaine dies', 'Daily walk prevents one in 10 early deaths - study', 'Greece train crash', 'Survivors describe nightmarish seconds as trains crashed', 'Greece train crash: What we know so far', 'Pictures show devastation after Greece train disaster', 'Drone footage of Greece train crash wreckage', 'Rescuers search wreckage of deadly Greece train crash', 'Must see', 'Blackpink lead top stars back on the road in Asia', 'BBC World News TV', 'BBC World Service Radio', 'Record numbers of guide dog volunteers after BBC story', 'Extremely fragile coronation chair being restored', 'Ancient mummy found in delivery mans bag', 'Finland starts construction of Russia border fence', 'Pilot circles plane to show passengers northern lights', 'Most watched', 'Full story', 'Exploring the rigging claims in Nigerias elections', 'Bola Tinubu - the godfather set to lead Nigeria', 'Why is Israel-Palestinian violence surging?', 'Ukraine war casts shadow over Indias G20 ambitions', 'The people who want you to believe the Ukraine war is fake', 'TikTok answers three cyber-security fears about app', 'Manchester bomber friend known to MI5, BBC reveals', 'Most read', 'Around the BBC', 'Playful fluffballs or rats of the sea?', 'The problem confronting women of colour', 'The return of the US lost language', 'The 1991 video game phenomenon', 'Why the world faces a genomic gap', 'A new way to navigate work and life', 'The Greek meatballs packed with history', 'Find us here', 'News daily newsletter', 'Mobile app', 'Get in touch', 'News Navigation', 'Explore the BBC']\n",
      "\n",
      "SoupList\n",
      "['BBC News Home', 'Accessibility links', 'News Navigation', 'Breaking Breaking news ', 'Top Stories', 'Greece train crash', 'Must see', 'Most watched', 'Full story', 'Most read', 'Around the BBC', 'Find us here', 'News Navigation', 'Explore the BBC', 'Greek transport minister resigns after deadly train crash', 'Greek transport minister resigns after deadly train crash', \"At the crash site of 'no hope' - BBC reporter in Greece\", 'Covid origin likely China lab incident - FBI chief', 'Why the Covid lab-leak theory is being taken seriously ', \"Ruling party wins Nigeria's presidential election\", 'Ed Sheeran says wife developed tumour in pregnancy', 'Uranium particles enriched to 83.7% found in Iran', 'Bieber cancels remaining Justice world tour dates', 'Man survives 31 days in jungle by eating worms', 'Kobe Bryant widow wins $29m settlement from LA', 'Denmark scraps holiday to boost defence budget', 'Kobe Bryant widow wins $29m settlement from LA', 'Denmark scraps holiday to boost defence budget', 'Israel cracks down on judicial reform protests', 'World Cup record holder Fontaine dies', 'Daily walk prevents one in 10 early deaths - study', \"Survivors describe 'nightmarish seconds' as trains crashed\", 'Greece train crash: What we know so far', 'Pictures show devastation after Greece train disaster', 'Drone footage of Greece train crash wreckage', 'Rescuers search wreckage of deadly Greece train crash', 'Blackpink lead top stars back on the road in Asia', 'BBC World News TV', 'BBC World Service Radio', 'Record numbers of guide dog volunteers after BBC story', 'Extremely fragile coronation chair being restored', \"Ancient mummy found in delivery man's bag\", 'Finland starts construction of Russia border fence', 'Pilot circles plane to show passengers northern lights', \"Exploring the rigging claims in Nigeria's elections\", \"Bola Tinubu - the 'godfather' set to lead Nigeria\", 'Why is Israel-Palestinian violence surging?', \"Ukraine war casts shadow over India's G20 ambitions\", 'The people who want you to believe the Ukraine war is fake', 'TikTok answers three cyber-security fears about app', 'Manchester bomber friend known to MI5, BBC reveals', 'Playful fluffballs or rats of the sea?', 'The problem confronting women of colour', \"The return of the US' lost language\", 'The 1991 video game phenomenon', \"Why the world faces a 'genomic gap'\", 'A new way to navigate work and life', 'The Greek meatballs packed with history', 'News daily newsletter', 'Mobile app', 'Get in touch', 'Related content']\n",
      "\n",
      "soupTopStories\n",
      "[\"At the crash site of 'no hope' - BBC reporter in Greece\", 'Covid origin likely China lab incident - FBI chief', 'Why the Covid lab-leak theory is being taken seriously ', \"Ruling party wins Nigeria's presidential election\", 'Ed Sheeran says wife developed tumour in pregnancy', 'Uranium particles enriched to 83.7% found in Iran', 'Bieber cancels remaining Justice world tour dates', 'Man survives 31 days in jungle by eating worms', 'Kobe Bryant widow wins $29m settlement from LA', 'Denmark scraps holiday to boost defence budget', 'Kobe Bryant widow wins $29m settlement from LA', 'Denmark scraps holiday to boost defence budget', 'Israel cracks down on judicial reform protests', 'World Cup record holder Fontaine dies', 'Daily walk prevents one in 10 early deaths - study', \"Survivors describe 'nightmarish seconds' as trains crashed\", 'Greece train crash: What we know so far', 'Pictures show devastation after Greece train disaster', 'Drone footage of Greece train crash wreckage', 'Rescuers search wreckage of deadly Greece train crash', 'BBC World News TV', 'BBC World Service Radio', 'Record numbers of guide dog volunteers after BBC story', 'Extremely fragile coronation chair being restored', \"Ancient mummy found in delivery man's bag\", 'Finland starts construction of Russia border fence', 'Pilot circles plane to show passengers northern lights', \"Bola Tinubu - the 'godfather' set to lead Nigeria\", 'Why is Israel-Palestinian violence surging?', \"Ukraine war casts shadow over India's G20 ambitions\", 'The people who want you to believe the Ukraine war is fake', 'TikTok answers three cyber-security fears about app', 'Manchester bomber friend known to MI5, BBC reveals', 'The problem confronting women of colour', \"The return of the US' lost language\", 'The 1991 video game phenomenon', \"Why the world faces a 'genomic gap'\", 'A new way to navigate work and life', 'The Greek meatballs packed with history']\n"
     ]
    }
   ],
   "source": [
    "##### -- Imports -- #####\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "##### -- Variables -- #####\n",
    "newsFront = 'https://www.bbc.com/news'\n",
    "\n",
    "##### -- Functions -- #####\n",
    "def getData(data):\n",
    "    response = requests.get(data)\n",
    "    contents = response.text\n",
    "    return contents\n",
    "\n",
    "def matches(data):\n",
    "    regexHeder = re.compile(r'<h\\d(?:.*?)>(.*?)<\\/h\\d>')\n",
    "    matches = regexHeder.findall(getData(data))\n",
    "    return matches\n",
    "\n",
    "def headerList(matchLst):\n",
    "    lst = []\n",
    "    for elements in matchLst:\n",
    "        elements = elements.replace(\"&#x27;\", '')\n",
    "        elements = re.sub(r'<span(?:.*?)>', '', elements)\n",
    "        elements = re.sub(r'<\\/span>', ' ', elements)\n",
    "        lst.append(elements)\n",
    "    return lst\n",
    "\n",
    "def cleaner(input):\n",
    "    lst = []\n",
    "    for elements in input:\n",
    "        elements = str(elements)\n",
    "        elements = re.sub(r'<h\\d(?:.*?)>', '', elements)\n",
    "        elements = re.sub(r'<\\/h\\d>', '', elements)\n",
    "        elements = re.sub(r'<span(?:.*?)>', '', elements)\n",
    "        elements = re.sub(r'<\\/span>', ' ', elements)\n",
    "        lst.append(elements)\n",
    "    return lst\n",
    "\n",
    "def soupHeders(data):\n",
    "    soup = BeautifulSoup(getData(data), 'html.parser')\n",
    "    soupList =  soup.find_all('h1') + soup.find_all('h2') + soup.find_all('h3') +  soup.find_all('h4')\n",
    "    return cleaner(soupList)\n",
    "\n",
    "def topStories(data):\n",
    "    soup = BeautifulSoup(getData(data), 'html.parser')\n",
    "    def find_all(tag):\n",
    "        return soup.find_all(tag, class_='gs-c-promo-heading__title gel-pica-bold nw-o-link-split__text') \n",
    "    soupList = find_all('h1') + find_all('h2') + find_all('h3') + find_all('h4') \n",
    "    return cleaner(soupList)\n",
    "\n",
    "\n",
    "##### -- Calls -- #####\n",
    "print(\"\")\n",
    "print(\"RequestList\")\n",
    "print(headerList(matches(newsFront)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"SoupList\")\n",
    "print(soupHeders(newsFront))\n",
    "\n",
    "print(\"\")\n",
    "print(\"soupTopStories\")\n",
    "print(topStories(newsFront))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (7-8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Describe the tools used and the challenges faced when creating the dataframe. </b> <br>\n",
    "When creating the articleList function, which returns a list of links referring to all the articles, the temp function uses the beautifulSoup html.parser and the find_all property to get a string with the content division element that contains all the needed links. Temp takes a letter as input and concatenates this letter to the Wikinews link. The following letters: K, L, M, N, O, P, R, S, T, and U are run on temp inside the articleList function by splitting the list from the assignment description and running it in a for-loop.\n",
    "\n",
    "The Pandas dataframe is created in the createTable function. A for-loop goes through all the links and readies the text for cleaning using request and bs4; the string is then fed to a tuple of functions that extract the relevant data. This data is then appended to a list and pasted into a Pandas dataframe.\n",
    "\n",
    "Of the three cleaning functions, getContent unraveled the most challenges. The first challenge was that the content consisted of multiple chunks of phrases. To deal with this defContent creates a list of all \\<p\\>'s and converts every list element into strings. The join function then unpacks the list to prepare a string for cleaning. This leads to the next challenge: cleaning the data in a helper function called cleanAll. cleanAll consists of regular expressions that remove the date and unwanted tags. When looking at the HTML code, I noticed that the content is always appearing before the tags \\<br\\>, \\<img\\>, and \\<b\\>. Therefore everything coming after one of these tags is removed.\n",
    "\n",
    "<b>Assess whether it is a reasonable choice to trust the sources when they aren't labeled. </b> <br>\n",
    "If it's assumed that whoever created the list of articles only included articles they believed were legit (or at least wanted the reader to think were legit), such labels would come from the same source and therefore have the same credibility. Because of this, the existence of labels doesn't matter.\n",
    "\n",
    "When using the list to practice programming skills, it doesn't matter either. The code would be identical if the articles were written in lorem ipsum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 header  \\\n",
      "0     K'nesset Member Natan Sharansky resigns from c...   \n",
      "1     Kaczynski elected as the new president of Pola...   \n",
      "2       Kaczyński takes the office of Polish president    \n",
      "3     Kansas Professor assaulted by angry intelligen...   \n",
      "4                Karachi, Pakistan shut down by strike    \n",
      "...                                                 ...   \n",
      "1881  UK defers junk food deals, advertisement restr...   \n",
      "1882  UK denies pressuring Scotland into Lockerbie r...   \n",
      "1883  UK drugs policy petition reaches 100,000 signa...   \n",
      "1884  UK economy shrinks by 0.3% in fourth quarter o...   \n",
      "1885  UK elections: David Cameron becomes Prime Mini...   \n",
      "\n",
      "                                date  \\\n",
      "0              Tuesday, May 3, 2005    \n",
      "1          Sunday, October 23, 2005    \n",
      "2         Friday, December 23, 2005    \n",
      "3         Tuesday, December 6, 2005    \n",
      "4              Monday, May 14, 2007    \n",
      "...                              ...   \n",
      "1881          Tuesday, May 17, 2022    \n",
      "1882   Wednesday, September 2, 2009    \n",
      "1883      Friday, February 14, 2014    \n",
      "1884       Friday, January 25, 2013    \n",
      "1885          Tuesday, May 11, 2010    \n",
      "\n",
      "                                                content  \n",
      "0      Sharansky’s resignation as Minister of Diaspo...  \n",
      "1      Lech Kaczyński has been elected as the new pr...  \n",
      "2                                                        \n",
      "3      Professor Paul Mirecki the chairman of the Re...  \n",
      "4      After two days of violence in Karachi Pakista...  \n",
      "...                                                 ...  \n",
      "1881   The United Kingdom Department of Health and S...  \n",
      "1882   Since the August 20 release of Abdelbaset Ali...  \n",
      "1883   The Backbench Business Committee of the House...  \n",
      "1884   The United Kingdom economy shrank by 0.3% in ...  \n",
      "1885   David Cameron was today appointed the new Bri...  \n",
      "\n",
      "[1886 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def cleanAll(input):\n",
    "    tag = ['p', 'span', 'a', 'i']\n",
    "    text = input\n",
    "    text = re.sub(r'(<strong(?:.*?)>).*(<\\/strong>)', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    for element in tag:\n",
    "        x = '<' + element + '(?:.*?)>'\n",
    "        y = '<\\/' + element + '>'\n",
    "        text = re.sub(x, '', text)\n",
    "        text = re.sub(y, ' ', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s,', '', text)\n",
    "    text = re.sub('\\<br(.*)', '', text)\n",
    "    text = re.sub('\\<img(.*)', '', text)\n",
    "    text = re.sub('\\<b(.*)', '', text)\n",
    "    return text\n",
    "\n",
    "def getHeader(input):\n",
    "    text = input.find('span', class_='mw-page-title-main')\n",
    "    text = str(text)\n",
    "    text = cleanAll(text)\n",
    "    return text\n",
    "\n",
    "def getDate(input):\n",
    "    text = input.find('strong', class_='published')\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<strong(?:.*?)>', '', text)\n",
    "    text = re.sub(r'<\\/strong>', ' ', text)\n",
    "    text = re.sub(r'<span(?:.*?)>', '', text)\n",
    "    text = re.sub(r'<\\/span>', ' ', text)\n",
    "    return text\n",
    "\n",
    "def getContent(input):\n",
    "    text = input.find_all('p')\n",
    "    lst = []\n",
    "    for elm in text:\n",
    "        elm = str(elm)\n",
    "        lst.append(elm)\n",
    "\n",
    "    string = ' '.join(lst)\n",
    "    string = cleanAll(string)\n",
    "    return string\n",
    "\n",
    "def articleList():\n",
    "    def temp(input):\n",
    "        page = 'https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&from=' + input\n",
    "        divGroup = BeautifulSoup(getData(page), 'html.parser')\n",
    "        divGroup = divGroup.find_all('div', id='mw-pages')\n",
    "        divGroup = divGroup[0].find_all('div', class_='mw-category-group')\n",
    "        divGroup = divGroup[0].find_all('a')\n",
    "        lst = []\n",
    "        for element in divGroup: \n",
    "            element = str(element)\n",
    "            href_regex = r'href=\"([^\"]+)\"'\n",
    "            element = re.search(href_regex, element)\n",
    "            element = element.group(1)\n",
    "            element = 'https://en.wikinews.org/' + element\n",
    "            lst.append(element)\n",
    "        return lst\n",
    "    letters = \"ABCDEFGHIJKLMNOPRSTUVWZABCDEFGHIJKLMNOPRSTUVWZ\"[10%23:10%23+10]\n",
    "    letters = [*letters]\n",
    "    lst = []\n",
    "    for elemement in letters:\n",
    "        elemement = temp(elemement)\n",
    "        lst = lst + elemement\n",
    "    return lst\n",
    "\n",
    "def createTable():\n",
    "    links = (articleList())\n",
    "    lst = []\n",
    "    for elm in links: \n",
    "        response = requests.get(elm)\n",
    "        contents = response.text\n",
    "        x = BeautifulSoup(contents, 'html.parser')\n",
    "        x = [getHeader(x), getDate(x), getContent(x)]\n",
    "        lst.append(x)\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    df.columns = ['header', 'date', 'content']\n",
    "    return df\n",
    "print(createTable())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas dateframe may look odd compared to part 1. This happens only in Jupyter and works correctly when the script is run in the command prompt. Note that I only refer to the visualization, not the actual structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75795907b8552c1b7c2d05e7431f51bc4164643b996c8972b31388240cae91af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
